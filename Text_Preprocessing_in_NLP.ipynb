{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCy6hwMcNpQY6p/kJNrOq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamuramit/Python-with-Machine-Learning-Concepts/blob/main/Text_Preprocessing_in_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUdVfJdcA4N4",
        "outputId": "3744db7a-43b3-4f27-da16-afad7080ebeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "#remove_accented_chars('Fiancee')\n",
        "remove_accented_chars('Fianc√©e')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o6by50BkBshq",
        "outputId": "3c9179eb-1af9-4cc1-f7d0-7c4befc13d0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fiancee'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a function to remove special characters and numbers\n",
        "def remove_special_characters_and_numbers(text):\n",
        "    # Define the pattern to match any character that is not a letter (a-z or A-Z)\n",
        "    pattern = r'[^a-zA-Z\\s]'\n",
        "    # Use re.sub() to Replace all non-letter charactermatches with an empty string\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "# Example Input\n",
        "input_text = \"Hello, World! Welcome to 2024. Let's clean this: $%#$%^&'' text.\"\n",
        "\n",
        "# Remove special characters and numbers from the input text\n",
        "cleaned_text = remove_special_characters_and_numbers(input_text)\n",
        "\n",
        "# Print the cleaned text\n",
        "print(f\"Original Text: {input_text}\")\n",
        "print(f\"Cleaned Text: {cleaned_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vjA45G8WF4nK",
        "outputId": "8870a708-67d9-4154-b8b5-c896c304722d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello, World! Welcome to 2024. Let's clean this: $%#$%^&'' text.\n",
            "Cleaned Text: Hello World Welcome to  Lets clean this  text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Text\n",
        "text = \"Hello, world! Welcome to the world of Text Processing with python.\"\n",
        "\n",
        "# Convert text to lowercase\n",
        "lowercase_text = text.lower()\n",
        "\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Lowercase Text: {lowercase_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "blWuS7ScGJ0z",
        "outputId": "13fcaa48-2f98-43a5-fc1b-8d89772a89cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello, world! Welcome to the world of Text Processing with python.\n",
            "Lowercase Text: hello, world! welcome to the world of text processing with python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Punctuation\n",
        "\n",
        "import string\n",
        "\n",
        "# Sample Text\n",
        "text = \"Hello, world! Welcome to the world of Text Processing with python.\"\n",
        "\n",
        "# Remove punctuation using string.punctuation\n",
        "text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Text without Punctuation: {text_without_punctuation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bf0YF8rlGnOU",
        "outputId": "15355c68-def3-4920-c867-8b4556261a57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello, world! Welcome to the world of Text Processing with python.\n",
            "Text without Punctuation: Hello world Welcome to the world of Text Processing with python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Sample Text\n",
        "text = \"Hello, world! Welcome to the world of Text Processing with python. NLTK is a great library for NLP tasks\"\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sentence Tokenization\n",
        "sentences  = sent_tokenize(text)\n",
        "print(\"Sentence Tokenizations\")\n",
        "print(sentences)\n",
        "\n",
        "# Word Tokenization\n",
        "words = word_tokenize(text)\n",
        "print(\"\\nWord Tokenizations\")\n",
        "print(words)\n",
        "\n",
        "#print(f\"Original Text: {text}\")\n",
        "#print(f\"Sentences: {sentences}\")\n",
        "#print(f\"Words: {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lEH4NwunG_Iq",
        "outputId": "1bf03e3c-ff68-4ace-c88f-b8193bc389b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenizations\n",
            "['Hello, world!', 'Welcome to the world of Text Processing with python.', 'NLTK is a great library for NLP tasks']\n",
            "\n",
            "Word Tokenizations\n",
            "['Hello', ',', 'world', '!', 'Welcome', 'to', 'the', 'world', 'of', 'Text', 'Processing', 'with', 'python', '.', 'NLTK', 'is', 'a', 'great', 'library', 'for', 'NLP', 'tasks']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "text_to_word_sequence('Hello, world! Welcome to the world of Text Processing with python. NLTK is a great library for NLP tasks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MV4JCQmNIjpz",
        "outputId": "398fc291-b44e-4b7a-912a-1256a560fcca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'world',\n",
              " 'welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'world',\n",
              " 'of',\n",
              " 'text',\n",
              " 'processing',\n",
              " 'with',\n",
              " 'python',\n",
              " 'nltk',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'library',\n",
              " 'for',\n",
              " 'nlp',\n",
              " 'tasks']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopword Removal\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample Text\n",
        "text = \"NLTK is a leading platform for building python programs to work with human language data.\"\n",
        "\n",
        "# Download neccesary NLTK Data files (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenize the text\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Get the list of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the text\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Filtered Text: {' '.join(filtered_words)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZzadK2S1Io6q",
        "outputId": "08b0b074-f471-4840-b58f-5d384c156213"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: NLTK is a leading platform for building python programs to work with human language data.\n",
            "Filtered Text: NLTK leading platform building python programs work human language data .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample Text\n",
        "text = \"NLTK is a leading platform for building python programs to work with human language data. Running, runners, and ran are related words.\"\n",
        "\n",
        "# Download neccesary NLTK Data files (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the text\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Initialize the Porter Stemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "# Apply stemming to each word in the text\n",
        "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
        "\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Stemmed Text: {' '.join(stemmed_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iziioy0JIpEa",
        "outputId": "6ff666f8-950c-404c-b593-6fbfb7cd9dd0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: NLTK is a leading platform for building python programs to work with human language data. Running, runners, and ran are related words.\n",
            "Stemmed Text: nltk is a lead platform for build python program to work with human languag data . run , runner , and ran are relat word .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}